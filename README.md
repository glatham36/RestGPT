# RestGPT

Great, I’ll explore how to create a text-to-API solution that converts natural language into REST or third-party API calls—targeted for business users or integration into LLM agent systems. I’ll look into existing tools, frameworks, and best practices, and cover how this could be implemented in a prototype or production-ready architecture. I’ll also examine whether it makes sense, where it’s most useful, and any potential pitfalls.

I’ll get back to you shortly with the findings.

# Natural Language to API Calls with LLMs

## Introduction  
Interfacing with APIs usually requires a precise knowledge of endpoints, parameters, and data formats – a barrier for non-technical users ([Harnessing LLMs for API Interactions: A Framework for Classification and Synthetic Data Generation](https://arxiv.org/html/2409.11703v1#:~:text=Traditionally%2C%20users%20interact%20with%20software%2C,16%20%2C%20%2032)). A **text-to-API** system leverages large language models (LLMs) to convert natural language instructions into API calls, letting users simply “ask” for an action or data and have the system call the appropriate REST or third-party API. Recent advancements indicate this is both technically feasible and practically useful. For example, GPT-4 has been fine-tuned to recognize when to invoke a function and output a JSON object with the right arguments ([Function Calling with LLMs | Prompt Engineering Guide<!-- --> ](https://www.promptingguide.ai/applications/function_calling#:~:text=LLMs%20like%20GPT,one%20in%20a%20single%20request)). Specialized models like **Gorilla** (a fine-tuned LLaMA-based model) demonstrate that LLMs can even surpass GPT-4 in generating correct API calls, largely by reducing hallucinated or incorrect usage ([[2305.15334] Gorilla: Large Language Model Connected with Massive APIs](https://arxiv.org/abs/2305.15334#:~:text=reasoning%20and%20program%20synthesis,issue%20of%20hallucination%2C%20commonly%20encountered)). In one study, GPT-4 achieved **99.6% accuracy** in mapping natural language commands to the correct API calls in a test setting ([Harnessing LLMs for API Interactions: A Framework for Classification and Synthetic Data Generation](https://arxiv.org/html/2409.11703v1#:~:text=developers%20or%20business%20owners%20to,and%20selection%20across%20diverse%20applications)), showing the high potential of these approaches. In short, with the right design, LLMs *can* reliably interpret user intents and translate them into structured API calls.

However, building a robust text-to-API pipeline comes with challenges. The LLM must generate **accurate endpoints and parameters** (e.g. correct function names, parameter types) and avoid hallucinating APIs that don’t exist ([[2305.15334] Gorilla: Large Language Model Connected with Massive APIs](https://arxiv.org/abs/2305.15334#:~:text=reasoning%20and%20program%20synthesis,issue%20of%20hallucination%2C%20commonly%20encountered)). It also needs mechanisms to handle multi-step operations (some user requests require calling several APIs in sequence) and to deal with errors or security constraints. Below, we explore use cases where text-to-API makes sense, design patterns to implement it, existing tools/frameworks that support it, and key considerations like security and error handling. We also contrast this with text-to-SQL systems and give recommendations for prototyping such a solution.

## Use Cases and Applications  
Text-to-API systems can empower both end-users and developers in a variety of scenarios:

- **Business User Automation:** Non-technical users can perform complex integrations or actions by describing what they want. For instance, *“Send a welcome email to all users who signed up today”* could trigger a sequence of CRM and email API calls, or *“Charge \$50 to John’s credit card using Stripe”* could invoke a Stripe API charge. Tools like Zapier’s Natural Language Actions already enable such use cases by giving access to 6000+ apps via natural language instructions ([AI Actions - Zapier](https://docs.zapier.com/platform/reference/ai-actions#:~:text=With%20the%20Natural%20Language%20Actions,API%2C%20you%20can)). This makes automation accessible to people who can’t write code.

- **Conversational Assistants with Tools:** Chatbots or virtual assistants use text-to-API to fetch live information or perform tasks on behalf of users. For example, a user might ask, *“What’s the weather in Belize?”* – the LLM can call a `get_current_weather` API and then respond with the result ([Function Calling with LLMs | Prompt Engineering Guide<!-- --> ](https://www.promptingguide.ai/applications/function_calling#:~:text=,that%20interact%20with%20a%20knowledge)). Similarly, a customer support bot could answer *“Where’s my order 231445?”* by calling an order status API ([Teaching AI to Call APIs: Exploring Function Calling | by Maximiliano Veiga | Medium](https://medium.com/@maximilianoneto/teaching-ai-to-call-apis-exploring-function-calling-bd9beb7aeccc#:~:text=,them%20into%20actionable%20API%20calls)). Instead of the conversation ending with an apology for lack of knowledge, the LLM actively retrieves the answer via an API call.

- **LLM-Based Agents and Workflows:** In more complex scenarios, an LLM agent can plan and execute *multiple* API calls in sequence to fulfill a high-level request. For instance, consider a request: *“Schedule a meeting with the new client next week and email me a summary of their last order.”* Fulfilling this might involve calling a CRM API to find the client’s details, a calendar API to create an event, and an orders API to retrieve the last order – then composing an email. An LLM can break the task into steps, call each API, and compile the result for the user. Research prototypes like **RestGPT** demonstrate this capability by connecting LLM agents with real-world apps (Spotify, Gmail, etc.) through sequences of RESTful API calls ([RestGPT: Connecting LLMs with RESTful APIs](https://restgpt.github.io/#:~:text=This%20work%20aims%20to%20construct,instructions%20with%20gold%20solution%20paths)).

 ([RestGPT: Connecting LLMs with RESTful APIs](https://restgpt.github.io/)) *An LLM agent fulfilling a user’s request with multiple Spotify API calls (searching an album by name, then adding it to the playback queue). This illustrates how a natural language command ("Play the album 'Bury The Hatchet'") can be decomposed into step-by-step API calls to achieve the goal ([RestGPT: Connecting LLMs with RESTful APIs](https://restgpt.github.io/#:~:text=RestGPT%20consists%20of%20three%20main,into%20two%20modules%3A%20a%20Caller)).*

- **Developer Assistance – Code Generation:** In some cases the goal is not to execute the API call now, but to help a developer write the correct code snippet. An LLM can translate a request like *“I need to connect to the Twilio API and send a text message”* into a code sample (in Python, JavaScript, etc.) that calls the appropriate endpoints. This is akin to GitHub Copilot suggesting integration code. It lowers the effort for developers to learn new APIs by providing ready-to-use examples. In fact, one benefit of LLMs noted in industry is that they can **generate API call code** from plain language descriptions ([LLMs might be used to create API calls, but don't reassign your data engineers yet.](https://www.proxet.com/blog/llms-might-be-used-to-create-api-calls#:~:text=2,can%20help%20reduce%20human%20error)). This reduces time spent searching documentation and helps avoid errors in crafting the call.

- **Enterprise Data Access:** Many enterprises expose data through microservices or APIs rather than direct database access. Text-to-API allows analysts or sales teams to query internal data via natural language, similar to text-to-SQL but targeting APIs. AWS, for example, describes AI assistants that handle *“creating API calls (text to API)”* alongside generating SQL, so that sales reps can query various data sources through a chat interface ([Boost sales team productivity and effectiveness with Sales Concierge on AWS | AWS for Industries](https://aws.amazon.com/blogs/industries/boost-sales-team-productivity-and-effectiveness-with-sales-concierge-on-aws/#:~:text=generating%20SQL%20queries%20,competitive%20intelligence%2C%20territory%20data%2C%20industry)). Instead of writing SQL or knowing multiple system interfaces, the user asks a question and the LLM decides which API (or combination of APIs) provides the answer. This can retrieve insights from CRMs, analytics services, or other business systems on the fly.

In summary, any scenario where a user (human or another system) needs to interact with a web service or backend **in real time** through natural language is a good candidate for text-to-API. This ranges from consumer-facing assistants (home automation: “turn the lights blue”) to internal tools (like a finance team querying invoice systems). The key advantage is improved accessibility and efficiency – the user expresses *what* they want, and the LLM figures out *how* to do it via API calls.

## Implementation Patterns and Architecture  
Building a text-to-API solution involves combining LLM capabilities with some representation of the available APIs. Several implementation patterns have emerged:

**1. Schema-Guided API Calls (Using OpenAPI or Function Definitions):** One robust approach is to formally define the API schema and let the LLM output a structured call that adheres to that schema. For example, OpenAI introduced *function calling* in mid-2023, where the developer provides the model with a set of function definitions (name, description, parameters in JSON Schema) corresponding to APIs. The LLM’s job is to decide if a user request warrants calling any of these functions, and if so, to produce a JSON object with the needed parameters ([Function Calling with LLMs | Prompt Engineering Guide<!-- --> ](https://www.promptingguide.ai/applications/function_calling#:~:text=LLMs%20like%20GPT,one%20in%20a%20single%20request)). Because the model was fine-tuned for this, it tends to produce a well-formed JSON for one of the allowed functions rather than free-form text. 

*How it works:* The system defines functions that wrap API endpoints. For instance, a Stripe charging API might be presented as: `create_charge(amount: number, currency: string, customer_id: string)`. If the user says “Charge \$50 to John’s card,” the model can output something like:  
```json
{ 
  "name": "create_charge", 
  "arguments": { "amount": 50, "currency": "USD", "customer_id": "cust_12345" } 
}
```  
This JSON can then be programmatically translated into an actual API call (e.g., an HTTP POST to `/v1/charges`). The LLM has effectively done the **natural language understanding** and mapping to structured parameters. Developers have used this pattern for things like weather queries (mapping “What is the weather in London?” to a `get_weather(location="London")` call) ([Function Calling with LLMs | Prompt Engineering Guide<!-- --> ](https://www.promptingguide.ai/applications/function_calling#:~:text=,that%20interact%20with%20a%20knowledge)) or database queries. In fact, one listed use case of function calling is precisely *“applications that convert natural language to API calls or valid database queries”* ([Function Calling with LLMs | Prompt Engineering Guide<!-- --> ](https://www.promptingguide.ai/applications/function_calling#:~:text=%2A%20LLM,that%20interact%20with%20a%20knowledge)).

The advantage of a schema-guided approach is that it **constrains the LLM** to use known endpoints and correct parameter formats, drastically reducing errors. OpenAPI specifications can serve as a schema source as well. If you have an OpenAPI (Swagger) doc for your API, you can feed that to the LLM (or a tool around it) so it knows the available endpoints, methods, and parameter names/types. Given an OpenAPI spec, an LLM can parse it and decide, for example, that *“Where’s my order 231445?”* should call the `GET /orders/{order_id}` endpoint with `order_id=231445`. There are libraries that automate this: **LangChain**, for instance, has an OpenAPI agent that ingests the API spec and enables the LLM to choose the right operation and fill in parameters ([Natural Language API Toolkits | ️ LangChain](https://python.langchain.com/docs/integrations/tools/openapi_nla/#:~:text=,and%20combine%20calls%20across%20endpoints)) ([Natural Language API Toolkits | ️ LangChain](https://python.langchain.com/docs/integrations/tools/openapi_nla/#:~:text=%1B,of%20Italian%20clothes%20are%20available)). The LangChain documentation refers to these as “**Natural Language API Toolkits**” which let agents *“plan and combine calls across endpoints”* given just a user query ([Natural Language API Toolkits | ️ LangChain](https://python.langchain.com/docs/integrations/tools/openapi_nla/#:~:text=,and%20combine%20calls%20across%20endpoints)). In practice, this involves prompt templates that provide context like: *“Here is the API specification. When the user asks something, identify the correct endpoint and format the call.”* The model’s output might be a pseudo-code or structured description of the API call, which the agent then executes.

**2. LLM as an Agent (ReAct Pattern and Planning):** When a single API call is not enough to satisfy a request, an LLM agent can break the problem into multiple steps. The **ReAct** framework (Reasoning and Acting) is commonly used here: the LLM alternates between thinking (generating a reasoning trace) and acting (making an API call as a tool), then observes the result and continues. Using ReAct, an agent might do something like: 

- Thought: “The user wants to play an album. I should search for the album first.”  
- Action: Call the search API (e.g., `GET /search?query="Bury The Hatchet"`).  
- Observation: The API returns an album ID.  
- Thought: “Now I have the ID, I should add the album to the playback queue.”  
- Action: Call the queue API (e.g., `POST /me/player/queue?album_id=XXX`).  
- Observation: API confirms success.  
- Thought: “All steps done, now I can confirm to the user.”  
- Final Answer: “I’ve added *Bury The Hatchet* to your queue, it should start playing shortly.”

This interleaving is orchestrated by the agent’s code, but the logic comes from the LLM’s outputs. LangChain’s agents implement a version of this: they have a specified format where the LLM must output `Action:` and `Action Input:`, etc., as seen in an example with a Klarna shopping API ([Natural Language API Toolkits | ️ LangChain](https://python.langchain.com/docs/integrations/tools/openapi_nla/#:~:text=%1B,of%20Italian%20clothes%20are%20available)). The agent checks the `Action` and executes it (real API call), then feeds the `Observation` (API response or summary of it) back into the LLM for the next Thought. This loop continues until the model produces a `Final Answer` for the user. 

The **RestGPT** project is an advanced example of an autonomous agent using this pattern for REST APIs. It consists of a *Planner*, an *API Selector*, and an *Executor*, each leveraging prompting strategies ([RestGPT: Connecting LLMs with RESTful APIs](https://restgpt.github.io/#:~:text=RestGPT%20consists%20of%20three%20main,into%20two%20modules%3A%20a%20Caller)). The **Planner** breaks the user request into sub-tasks (in plain language) if needed; the **API Selector** maps those sub-tasks to specific API calls (consulting the API documentation/spec); and the **Executor** actually calls the APIs and parses the responses. Notably, RestGPT’s executor had a *Caller* module that uses the API documentation to format the call correctly, and a *Parser* module that generates code to parse the API response based on the schema ([RestGPT: Connecting LLMs with RESTful APIs](https://restgpt.github.io/#:~:text=planner%20decomposes%20user%20instructions%20into,response%20schema%20defined%20in%20OAS)). This design shows how an agent can dynamically adapt – planning step-by-step rather than generating a fixed sequence upfront, which is important if later API results change what you do next. It also highlights that response parsing can be learned (the LLM can output code to extract needed info from a JSON response, for example).

 ([RestGPT: Connecting LLMs with RESTful APIs](https://restgpt.github.io/)) *Architecture of a text-to-API agent (from the RestGPT system). A **Planner** component breaks a user query into sub-tasks, an **API Selector** chooses the appropriate endpoints (using an OpenAPI spec as reference), and an **Executor** handles the API calls. The Executor here is split into a **Caller** (formulating HTTP requests using API docs) and a **Parser** (interpreting responses according to the schema) ([RestGPT: Connecting LLMs with RESTful APIs](https://restgpt.github.io/#:~:text=RestGPT%20consists%20of%20three%20main,into%20two%20modules%3A%20a%20Caller)). This modular design helps the agent handle multi-step instructions and adapt its plan based on API results.*

**3. Retrieval-Augmented or Fine-Tuned Models:** Another pattern is to fine-tune an LLM on a corpus of API documentation and example calls so that it *learns* how to compose valid calls in a single shot. The **Gorilla** model is a prime example: it was trained on a large collection of API references (HuggingFace Hub, TorchHub, etc.) and corresponding usage examples ([[2305.15334] Gorilla: Large Language Model Connected with Massive APIs](https://arxiv.org/abs/2305.15334#:~:text=document%20retriever%2C%20Gorilla%20demonstrates%20a,model%2C%20data%2C%20and%20demo%20are)). Given a natural language request, Gorilla directly outputs the best API call (including choosing the right function and arguments) that fits the request. A key innovation in Gorilla is using a *document retriever* – at query time, it fetches relevant API documentation and feeds it to the model, so the model stays up-to-date and is less likely to hallucinate an outdated function signature ([[2305.15334] Gorilla: Large Language Model Connected with Massive APIs](https://arxiv.org/abs/2305.15334#:~:text=today%27s%20state,consisting%20of%20HuggingFace%2C%20TorchHub%2C%20and)) ([[2305.15334] Gorilla: Large Language Model Connected with Massive APIs](https://arxiv.org/abs/2305.15334#:~:text=document%20retriever%2C%20Gorilla%20demonstrates%20a,the%20model%27s%20ability%2C%20we%20introduce)). The result is that Gorilla can generalize to many APIs and versions: *“Given a natural language query, Gorilla comes up with the semantically- and syntactically-correct API to invoke.”* ([GitHub - ShishirPatil/gorilla: Gorilla: Training and Evaluating LLMs for Function Calls (Tool Calls)](https://github.com/ShishirPatil/gorilla#:~:text=Gorilla%20enables%20LLMs%20to%20use,correct%20API%20to%20invoke)) Fine-tuning and retrieval help ensure correctness, and indeed Gorilla was shown to reduce mistakes compared to prompting GPT-4 directly ([[2305.15334] Gorilla: Large Language Model Connected with Massive APIs](https://arxiv.org/abs/2305.15334#:~:text=reasoning%20and%20program%20synthesis,issue%20of%20hallucination%2C%20commonly%20encountered)).

Organizations with specific APIs can adopt a similar approach: compile a dataset of (user request → correct API call) pairs and fine-tune a smaller LLM on it, or use in-context learning with examples. This is analogous to natural language to SQL training, but for API calls. There is also research on *classifying* an NL request to an API call template (intent classification) and then filling slots; one framework achieved high accuracy on classification by using GPT-4 for that step ([Harnessing LLMs for API Interactions: A Framework for Classification and Synthetic Data Generation](https://arxiv.org/html/2409.11703v1#:~:text=interactions,suitability%20of%20LLMs%20for%20customized)) ([Harnessing LLMs for API Interactions: A Framework for Classification and Synthetic Data Generation](https://arxiv.org/html/2409.11703v1#:~:text=developers%20or%20business%20owners%20to,and%20selection%20across%20diverse%20applications)). In practice, combining retrieval with an LLM (to get the latest API specs) and then letting the LLM produce the call is a promising way to handle large or frequently changing API sets.

**4. Mapping Language to Parameters:** A common challenge is extracting or converting parts of the user’s request into the precise parameters an API expects. LLMs are quite good at this sort of semantic parsing – especially if the parameter names are intuitive or the API documentation is provided. For example, a user says, *“Where is my order 231445?”* and the API needs `order_id`. The model should infer that “231445” is the value for `order_id`. This usually works implicitly, but can be improved with prompt engineering (e.g., “The API expects an `order_id`. Find if the user mentioned any order number.”). Tools can also do a pre-processing step – for instance, using regex to find patterns like IDs, dates, etc., and then letting the LLM confirm where they go. Another trick is using few-shot examples in the prompt: show the model a couple of dialogues where a query is turned into a JSON with parameters. This guides it to do the same for new queries.

In cases where the mapping is complex (e.g., user says “the second week of next month” and the API expects an exact date range), developers might incorporate a calendar utility or a separate parsing function. But generally, one of the strengths of modern LLMs is understanding context and entities, which helps mapping free-form language to structured fields.

## Existing Tools and Frameworks  
Thanks to the popularity of LLM “agents” and plugins, there are many emerging frameworks and products for text-to-API integration:

- **OpenAI Function Calling / ChatGPT Plugins:** OpenAI’s API allows developers to register functions or plugin endpoints that the model can call. The model (GPT-4 or GPT-3.5 fine-tuned for this purpose) will output a function name and arguments in JSON when appropriate ([Function Calling with LLMs | Prompt Engineering Guide<!-- --> ](https://www.promptingguide.ai/applications/function_calling#:~:text=LLMs%20like%20GPT,one%20in%20a%20single%20request)). For example, the ChatGPT *weather* plugin defines a function `get_current_weather(location, unit)` – if a user asks about weather, ChatGPT returns a function call like `get_current_weather("Belize", "celsius")`. The developer’s code receives this, calls the real weather API, and returns the result to ChatGPT, which then presents it to the user. This approach is available commercially (ChatGPT plugins, Azure OpenAI service functions, etc.) and is one of the most straightforward ways to implement text-to-API for a set of known functions. It’s particularly powerful for single-step operations and question-answering scenarios.

- **LangChain and Agent Frameworks:** LangChain provides out-of-the-box toolkits for connecting to APIs via natural language. One is the *OpenAPI Toolkit*, which, given an OpenAPI spec URL, will create an agent that can autonomously pick and call API operations ([Natural Language API Toolkits | ️ LangChain](https://python.langchain.com/docs/integrations/tools/openapi_nla/#:~:text=,and%20combine%20calls%20across%20endpoints)). Under the hood it uses the ReAct loop with the spec as context. Another is the *Zapier NLA (Natural Language Actions) tool* integration ([Zapier Natural Language Actions | 🦜️ LangChain](https://python.langchain.com/docs/integrations/tools/zapier/#:~:text=Zapier%20Natural%20Language%20Actions%20,a%20natural%20language%20API%20interface)). Zapier’s NLA is a service that exposes thousands of third-party app actions (Salesforce, Gmail, Slack, etc.) to LLMs, so you can say something like “add a row to the spreadsheet for a new customer” and behind the scenes it uses the Google Sheets API. LangChain’s Zapier tool allows an agent to access those 5k+ apps and 20k+ actions through Zapier’s unified API ([Zapier Natural Language Actions | 🦜️ LangChain](https://python.langchain.com/docs/integrations/tools/zapier/#:~:text=Zapier%20Natural%20Language%20Actions%20,a%20natural%20language%20API%20interface)). Other agent frameworks (like Microsoft’s Guidance, Google’s PaLM API tools, etc.) have similar capabilities to incorporate external API calls. Essentially, these frameworks handle the prompt formating, function spec ingestion, and sometimes the actual HTTP request, so you as a developer just plug in your API credentials and get a text-to-API agent running quickly.

- **Gorilla (API-Calling LLM):** Discussed earlier, Gorilla is an open-source model specialized for API call generation ([[2305.15334] Gorilla: Large Language Model Connected with Massive APIs](https://arxiv.org/abs/2305.15334#:~:text=reasoning%20and%20program%20synthesis,issue%20of%20hallucination%2C%20commonly%20encountered)). The team also provides a **GoEx** execution engine ([GitHub - ShishirPatil/gorilla: Gorilla: Training and Evaluating LLMs for Function Calls (Tool Calls)](https://github.com/ShishirPatil/gorilla#:~:text=,loop.%20%5BBlog%5D%20%5BCode%5D%20%5BPaper%5D%20%5BTweet)) – which not only generates calls but can execute and validate them. Gorilla is a good starting point if you prefer an on-premise solution and have a defined set of APIs (e.g., internal enterprise APIs). Instead of writing prompts for each function, you can let Gorilla handle a broad range of calls. It’s worth noting Gorilla’s focus has been on machine-learning related APIs (Torch, TF, etc.) for their benchmarks, but the approach can extend to any APIs given training data. The project has a growing community, a leaderboard for function-calling tasks, and even a “API store” concept for sharing new API specs ([GitHub - ShishirPatil/gorilla: Gorilla: Training and Evaluating LLMs for Function Calls (Tool Calls)](https://github.com/ShishirPatil/gorilla#:~:text=Gorilla%20enables%20LLMs%20to%20use,correct%20API%20to%20invoke)). This indicates an active effort to make LLMs better at tool use.

- **RestGPT and Other Research Prototypes:** While not off-the-shelf libraries, projects like **RestGPT** ([RestGPT: Connecting LLMs with RESTful APIs](https://restgpt.github.io/#:~:text=This%20work%20aims%20to%20construct,instructions%20with%20gold%20solution%20paths)) and others (e.g., Amazon’s plans for multi-step API calling ([Enabling LLMs to make the right API calls in the right order](https://www.amazon.science/blog/enabling-llms-to-make-the-right-api-calls-in-the-right-order#:~:text=Enabling%20LLMs%20to%20make%20the,Given%20a%20prompt%2C%20we)), Microsoft’s guidance on Toolformer, etc.) are valuable references. RestGPT in particular has open-source code ([RestGPT: Connecting LLMs with RESTful APIs](https://restgpt.github.io/#:~:text=The%20code%20is%20released%20in,Song793%2FRestGPT)) that demonstrates how to integrate an LLM with real services (Spotify, Slack, Gmail...). There’s also overlap with the ideas from **text-to-SQL** research – for instance, one paper “Adapting LLMs for API integration” explores different strategies to map NL to API calls, analogous to how NL2SQL systems have been built ([[PDF] Adapting LLMs for Structured Natural Language API Integration](https://aclanthology.org/2024.emnlp-industry.74.pdf#:~:text=,4A%20video)) ([Enabling LLMs to make the right API calls in the right order](https://www.amazon.science/blog/enabling-llms-to-make-the-right-api-calls-in-the-right-order#:~:text=order%20www,Given%20a%20prompt%2C%20we)). Many of these prototypes use a combination of prompt engineering, dynamic planning, and knowledge of the API specs to improve reliability.

- **Commercial Platforms:** Besides OpenAI’s plugin ecosystem, some companies offer products for natural language enterprise integration. For example, **Zapier’s Natural Language Actions** (as mentioned) allows integration within chatbots or custom apps ([AI Actions - Zapier](https://docs.zapier.com/platform/reference/ai-actions#:~:text=With%20the%20Natural%20Language%20Actions,API%2C%20you%20can)). There are also low-code platforms adding AI features (like enabling a user to describe a workflow in plain language, which the system then configures with the necessary API calls). These often combine an LLM with existing workflow automation tech. Another example is Salesforce’s Einstein GPT, which aims to let salespeople use natural language for CRM actions – under the hood it likely maps to Salesforce API calls. While details can vary, the core idea is consistent: a layer that translates NL into API calls, often with humans confirming critical steps.

In choosing a tool or framework, consider the scope of APIs needed and whether you require real-time autonomous action or just suggestions. If you have a small set of internal APIs, using OpenAI function calling with a well-crafted spec might suffice. For a broad range of third-party APIs, an agent approach with something like Zapier NLA or a Gorilla-based solution could be better.

## Security, Authentication, and Error Handling  
Opening up API execution to an LLM requires careful guardrails:

- **Authentication:** API keys or credentials should not be given to the LLM in plaintext (both for security and because the model might inadvertently output them). Instead, handle auth in the execution layer. For instance, if the LLM says to call `create_charge(amount, customer_id)`, your code inserts the secret API key in the HTTP header when making the request to Stripe. This way the model never “sees” the key, it just knows it can call `create_charge`. In systems like ChatGPT plugins, the user authenticates via OAuth or similar, and the plugin store handles tokens – the model only gets a token ID or nothing at all. Also, restrict what the LLM can do with dynamic values in calls; e.g., if the LLM somehow output a different endpoint or URL, your system should reject it unless it matches the allowed pattern (to prevent it from exfiltrating data to an attacker’s server, for example).

- **Permissions and Scope:** Ensure the LLM agent can only call APIs that the user is allowed to use. For multi-user systems, integrate with your permission system. If a user shouldn’t delete records, the agent should not have a function for that (or it should require an extra confirmation). One strategy is to implement a *policy layer* that reviews a proposed action. For example, before executing `delete_user(user_id)`, the system could require an “are you sure?” confirmation from the user or check a permission flag. This prevents an LLM from doing something destructive based on a misunderstood instruction or malicious prompt.

- **Input Validation:** Because the LLM might misconstrue a value or unit, it’s good to validate arguments before making the API call. If the API expects an integer and the model passed a string, or if an email address doesn’t match a regex, catch it and either correct it or ask the LLM to fix it. Many function-calling frameworks will do basic type checking (e.g., OpenAI’s function calling will not return a call if the JSON doesn’t conform to the specified schema – the model is forced to try again). You can also have the execution layer perform sanity checks: e.g., if it’s going to call an endpoint with a very large number or a blank required field, flag that as an error.

- **Error Handling and Recovery:** Even with a correct API call, things can go wrong – the external service might be down, or the request returns an error (like “customer_id not found”). The system should catch exceptions or HTTP errors and feed that information back to the LLM or to a fallback routine. A well-designed agent can handle errors by analyzing them and maybe attempting a different approach. For instance, if a call to a weather API fails, the agent could try an alternative API or inform the user of the failure gracefully. In a simpler setup, you might just present the error message to the user or log it for developers. It’s important to avoid scenarios where the LLM thinks it succeeded when the action actually failed – thus always check the API response status. Some frameworks allow you to define how to turn errors into model input. For example, you could prompt the LLM with: *“The API call failed with error: rate limit exceeded. How would you like to proceed?”* in an agent loop.

- **Preventing Hallucinated or Undesired Calls:** An LLM might try to call an API that doesn’t exist or use parameters in the wrong way (especially if it wasn’t sufficiently constrained). To mitigate this, **whitelisting** allowed endpoints is crucial. If using function calling, only registered functions can be called – problem solved. If using a more free-form agent with an OpenAPI spec, you can parse the model’s intended call and ensure the endpoint and parameters appear in the spec. If not, you refuse execution. This way, even if the model “hallucinates” an endpoint (perhaps it assumed an API has a feature that it doesn’t), your system won’t execute it blindly. Instead, you might prompt the model that it was invalid and let it try again or apologize to the user.

- **Auditing and Limits:** Log every API call an LLM initiates, along with the prompting context if possible. This helps in debugging and monitoring for misuse. If the system is interactive, consider rate-limiting how many calls it can do in a short time, to avoid runaway loops or abuse (for instance, if a prompt injection tricked the agent into calling something repeatedly). For sensitive actions (like financial transactions), you might implement a **confirmation step** – the agent drafts the action, but asks the user “Do you want to proceed with this payment?” before actually executing. While this adds friction, it can be important for safety until the system has proven accuracy.

- **Sandboxing and Post-facto Validation:** Research is ongoing into sandboxing LLM-initiated actions. The **GoEx** runtime from the Gorilla team is an example where they execute LLM-generated code/API calls in a controlled environment and use *post-facto validation* – basically checking after execution whether the action had the intended effect and no unintended side-effects ([GitHub - ShishirPatil/gorilla: Gorilla: Training and Evaluating LLMs for Function Calls (Tool Calls)](https://github.com/ShishirPatil/gorilla#:~:text=,loop.%20%5BBlog%5D%20%5BCode%5D%20%5BPaper%5D%20%5BTweet)). They even explore an “undo” mechanism ([GitHub - ShishirPatil/gorilla: Gorilla: Training and Evaluating LLMs for Function Calls (Tool Calls)](https://github.com/ShishirPatil/gorilla#:~:text=,loop.%20%5BBlog%5D%20%5BCode%5D%20%5BPaper%5D%20%5BTweet)) for reversible actions, and *damage confinement* to limit what a misbehaving agent could do. While such advanced features may not be in initial prototypes, the takeaway is to design the system such that if something goes wrong (say the LLM tried to delete the wrong record), there’s a way to roll it back or at least prevent it from doing more damage. At minimum, keep the human in the loop for critical operations.

- **Latency and Timeouts:** When the LLM requests an API call, that can introduce delays (waiting for an external API). Make sure to handle timeouts and not freeze the conversation if an API is slow. You might need to inform the user “This is taking longer than expected...” or design the agent to multitask (some advanced agents could parallelize calls if independent). For a business user facing tool, responsiveness is key – you might prioritize calls that are quick, and for long-running tasks perhaps delegate them to background jobs and inform the user later.

In summary, treat the LLM-driven actions as you would a new, somewhat unpredictable user of your API: apply the same security and validation measures. Principle of least privilege (only allow what’s necessary), robust error checks, and transparency in what was done will go a long way. By layering the LLM with a deterministic execution harness, you get the benefits of natural instruction with much lower risk of unintended effects.

## When to Generate Code Snippets vs. Executing API Calls  
Depending on the context, you may prefer the LLM to **output code** for an API call rather than actually call the API. Each approach has its benefits:

- **Generating Code Snippets:** This is useful when the end goal is to help a developer or to document how to use an API. For instance, an LLM-based assistant in an IDE could respond to “I need to send an SMS with Twilio” by producing a code snippet in Python or Java that the developer can review and incorporate. The advantages here are transparency and control – the user sees exactly what will run. It’s also safer in the sense that the LLM isn’t directly executing anything in production; a human reviews the code and runs it. Furthermore, the code snippet can be reused, modified, and checked into source control like any other code. Many coding assistants (Copilot, CodeGPT, etc.) function this way, by inserting or suggesting code rather than running it. One point made by practitioners is that LLMs can **eliminate boilerplate** and help “glue” APIs together in code form ([LLMs might be used to create API calls, but don't reassign your data engineers yet.](https://www.proxet.com/blog/llms-might-be-used-to-create-api-calls#:~:text=API%20calls%20%E2%80%94%20one%20application,and%20cost%20of%20enterprise%20solutions)) ([LLMs might be used to create API calls, but don't reassign your data engineers yet.](https://www.proxet.com/blog/llms-might-be-used-to-create-api-calls#:~:text=1,snippets%20based%20on%20your%20requirements)) – essentially writing the integration code that a human would otherwise write manually. Another scenario for codegen is when the user’s environment can’t directly run the call (maybe due to lack of network access), but they just want to see how it *would* be done.

- **Executing API Calls Directly:** This is the approach for end-user-facing agents or automation, where the whole point is to save the user from having to do it themselves. If a salesperson says “Add Acme Corp as a new lead in Salesforce,” they likely want the action done, not a code sample. Direct execution provides immediate results – the record gets created and the assistant can confirm “Acme Corp has been added to your leads.” It closes the loop in one interaction. This is also crucial for agent systems that need real-time information (e.g., fetching current data or performing transactions as part of a larger task). The downside is you need all the safety nets discussed above, and you need to trust the LLM’s output to some degree. For internal tools or controlled environments, this can be acceptable. For public-facing scenarios, it’s common to combine execution with confirmation (“Shall I proceed?”) to be safe.

Often, a system can support both modes: Perhaps a user has the option *“Preview code”* versus *“Run”*. For example, an LLM could produce a SQL query and either show it to an analyst or actually run it on the database depending on user choice. Similarly, a text-to-API interface might by default show the API request it’s going to make (for transparency), and the user can hit “execute” to perform it. This hybrid approach is reassuring for users who want to verify actions. In contrast, a fully automated agent (say in an IoT setting) would just execute behind the scenes.

As a rule of thumb, **generate code when the user’s intent is to learn or develop**, and **execute calls when the user’s intent is to get a result now**. The former treats the LLM as a smart documentation tool, the latter treats it as an autonomous agent or command executor. Both leverage the same underlying capability (natural language understanding and API formatting), but they serve different user needs. It’s not a strict dichotomy – some systems log every executed call as code anyway (for audit or replay), blurring the line between just returning code and running it.

## Comparison to Text-to-SQL Systems  
Text-to-API and text-to-SQL share the goal of translating natural language into a formal query that a machine can execute. Techniques from years of text-to-SQL research and products certainly inform how we do text-to-API:

**Similarities:**  
- **Schema/Spec Awareness:** Just as text-to-SQL systems ingest a database schema (tables, columns, relationships) to guide the query generation, a text-to-API system uses API specifications (endpoints, parameters, allowed values) to guide call generation. In both cases, the model must align the user’s words to the schema (be it a table or an endpoint). For instance, the user asks for “total sales last month” – the SQL system looks for a `sales` table/column, while the API system might look for a `/sales` endpoint. The underlying challenge of grounding natural language in a predefined schema is common to both.

- **Natural Language Understanding:** Both require parsing potentially ambiguous requests. “Show me all orders from Acme” – one system might produce `SELECT * FROM Orders WHERE customer='Acme';`, another might hit `GET /orders?customer=Acme`. They need to recognize entities (“Acme” is a customer) and the desired output (list of orders). LLMs have improved the state of the art in both domains by bringing strong language understanding, which can handle synonyms or implicit references that rule-based systems struggled with.

- **Use of Examples and Fine-tuning:** Early text-to-SQL used supervised learning on labeled pairs (NL question, SQL query). The same can be done for APIs: pairs of NL request and API call. In fact, an API call could be seen as a more flexible “query” that could do writes, etc. Fine-tuning or few-shot prompting works similarly – you show how a couple of natural requests map to formal queries or calls, and the model learns to mimic that pattern on new inputs. So, development-wise, if you have experience building text-to-SQL, the workflow of collecting data and training might directly extend to text-to-API.

- **Goal of Empowering Non-Experts:** Ultimately, both systems aim to let users who don’t know the formal language (SQL or API syntax) still get what they need. As one paper noted, allowing users to interact with software through natural language *“makes systems more intuitive and accessible to users of varying technical expertise”* ([Harnessing LLMs for API Interactions: A Framework for Classification and Synthetic Data Generation](https://arxiv.org/html/2409.11703v1#:~:text=Programming%20Interfaces%20,16%20%2C%20%2032)) – this applies equally whether the backend is a database or a microservice. In enterprise settings, one might use both: text-to-SQL for direct database queries and text-to-API for interacting with services that have no direct database access.

**Differences:**  
- **Action vs. Query:** A notable difference is that APIs often perform actions (creating, updating, deleting data, or triggering processes) in addition to retrieving data. SQL can modify data too, but many text-to-SQL use cases focus on SELECT queries (read-only analytics). Text-to-API has to handle side effects more carefully. Executing *“delete all users”* via an API is clearly higher stakes than a read query. This is why confirmation and safety take an even bigger role in text-to-API. The potential impact of a generated API call can be broader (integrating with external systems, sending emails, charging money, etc.) compared to a typical SQL query confined to a database.

- **Multi-step Processes:** In databases, a single SQL query can answer many complex questions if written correctly (join multiple tables, aggregate, etc.). With APIs, if the information isn’t all provided by one endpoint, the agent might need to call multiple endpoints and combine the results. For example, to get “the total sales of Acme Corp in 2023”, a SQL might join customers and orders in one query, whereas an API-based approach might require first calling `GET /customers?name=Acme` to find Acme’s ID, then calling `GET /orders?customer_id=123&year=2023`, then summing the amounts. This sequential nature of API calls means text-to-API agents often need a planning ability that text-to-SQL systems don’t always require (though some complex NL questions to SQL might involve multi-query reasoning or external tools, it’s less common).

- **Standardization:** SQL is a standardized language (with dialect variations), whereas APIs are highly variable in design. This means a text-to-SQL model can target “SQL” as a general skill, but a text-to-API model usually needs to be customized or provided context for the specific API in question. OpenAPI helps standardize the way to describe APIs, but the actual operations and parameters are domain-specific. Thus, text-to-API solutions often need the specific API documentation at runtime or training time. This is akin to each database having a different schema – but in APIs, the differences can be more drastic (one API might use REST, another GraphQL, etc., though here we mainly consider REST/HTTP endpoints for consistency).

- **Error Handling:** When a generated SQL query is wrong, it might fail to execute or just return wrong data; but it typically doesn’t make partial changes before failing. With API calls, especially if an agent is making a sequence of calls, one failing in the middle can leave the system in a partial state (some actions done, others not). This is more like transaction management in databases. A text-to-API agent may need to handle rollback or compensation logic explicitly, whereas text-to-SQL doesn’t modify state as often (unless doing transactions).

Despite these differences, the success of text-to-SQL systems over the years (from research benchmarks to products like Salesforce’s NL2SQL or Microsoft’s AI in PowerBI) is a positive sign for text-to-API. It shows that with the combination of schema knowledge and strong language models, natural language can be reliably mapped to formal actions. In fact, one could view text-to-API as a general superset: a SQL query is just one kind of API call (to a database). Already, cloud providers and tools are merging these ideas under broader “natural language to data” initiatives ([Text-to-SQL? How about Text-to-API (or Lambda or Microservice or SOAP web service or RESTful service or ...) · run-llama llama_index · Discussion #11262 · GitHub](https://github.com/run-llama/llama_index/discussions/11262#:~:text=I%20watched%20the%20good%20video,that%27s%20accessed%20should%20be%20immaterial)) ([Text-to-SQL? How about Text-to-API (or Lambda or Microservice or SOAP web service or RESTful service or ...) · run-llama llama_index · Discussion #11262 · GitHub](https://github.com/run-llama/llama_index/discussions/11262#:~:text=What%20does%20it%20take%20to,contain)). 

## Recommendations for Building a Prototype  
If you want to build a text-to-API solution, here’s a roadmap and tips to get started:

1. **Define the Scope and APIs:** Start by narrowing down which API(s) the system will handle. Is it a specific third-party service (e.g., Twilio, Stripe), a set of internal microservice endpoints, or an open-ended set? For a prototype, having a well-defined small set of APIs with clear OpenAPI specs or documentation is ideal. You might begin with a single API (like a weather API or a company’s internal HR API) to prove the concept.

2. **Choose an Approach:** The quickest way to get something working is using a hosted LLM with function calling (if you have access to OpenAI GPT-4 or AnthropIC Claude, etc.). Define the functions corresponding to your API actions and let the model do the heavy lifting of producing a call. If you prefer an open-source route, consider using LangChain’s OpenAPI agent or even the Gorilla model. For instance, **LangChain’s OpenAPI agent** can be initialized with just a link to your API’s Swagger YAML and an LLM like GPT-3.5 or GPT-4 – it will then parse user questions and route to the API calls ([Natural Language API Toolkits | ️ LangChain](https://python.langchain.com/docs/integrations/tools/openapi_nla/#:~:text=,and%20combine%20calls%20across%20endpoints)). This saves you from writing a lot of prompt logic yourself. On the other hand, if your use case is very domain-specific and you need on-prem capability, a fine-tuned model approach (like training a smaller LLM on your API patterns) could be worth exploring after an initial prototype.

3. **Implement a Basic Loop:** At its core, the system will do the following in a loop or sequence:
   - **Accept user input** (the NL instruction).
   - **LLM Processing:** Either directly get an API call from the LLM (function call or formatted text) or get a plan of action.
   - **Execute the API call(s):** Your code takes the output and performs the actual HTTP requests to the target API(s).
   - **Post-process results:** Format the API responses into a user-friendly reply (this might involve feeding the raw response back into the LLM to summarize or format).
   - **Return answer to user.**  
   
   For a simple single-call case, you might integrate this in a single step. For a multi-step, you’d loop with the agent approach. It’s often wise to start with the simplest scenario (one call per user query) to validate correctness, then add complexity.

4. **Use Prompting Wisely:** If not using the structured function calling, design prompts that clearly tell the LLM what to do. Provide examples: e.g., *“User says X” → *“Call API Y with parameters…”*. One effective pattern is to instruct the model to output a JSON or a specific format that your program can easily parse. For example:  
   **System prompt:** *“You are an assistant that converts instructions into API calls. The available API is: POST /send_sms with parameters: `number` (phone number), `message` (text). When the user requests an action, provide a JSON with the fields `endpoint` and `params`.”*  
   **User:** *“Send a greeting to 555-1234.”*  
   **Assistant:** *```{"endpoint": "/send_sms", "params": {"number": "555-1234", "message": "Hello from our service!"}}```*  
   
   This output can be easily parsed by your code to actually call the API. By constraining the format, you reduce the chance of free-form irrelevant text. If the model’s response doesn’t parse, you can detect that and maybe re-prompt or throw an error.

5. **Test with Diverse Examples:** Try paraphrasing the same request in different ways and see if the LLM still does the right thing. Also test edge cases (no parameter given when one is needed, or asking for something outside the API’s capability). This will reveal where your prompt or model might be lacking. You can then refine the prompt or add more few-shot examples to cover those. If using function calling, check how the model responds to tricky inputs – it might sometimes return a natural answer instead of a function if it thinks it doesn’t need the function. Tweak the instructions or user prompt to encourage the desired behavior (OpenAI allows a flag like “force function call” which can be used carefully for debugging).

6. **Incorporate Confirmation for Irreversible Actions:** In the prototype, you can simulate this by always printing out “Proposed API call: … Execute? (y/n)” in your interface. This not only protects you during development (so you don’t accidentally send an email to all customers due to a mis-parse!), but also lets you see what the LLM is trying to do before it does it. Over time, as confidence grows, you could remove some confirmations, but keeping a manual step initially is prudent.

7. **Logging and Debugging:** Log every interaction, especially the LLM’s generated call and the API response. During testing, you’ll likely find mismatches (e.g., the model thought an ID was a name or vice versa). These logs help you understand model mistakes and correct them via prompt or code adjustments. Additionally, if using retrieval (like feeding in docs), ensure you log what docs were retrieved so you know what context the model saw.

8. **Iterate or Expand:** Once the basic flow works for one API, you can expand to more endpoints or integrate multiple services. This might involve weighting decisions – e.g., if two APIs could answer a question (maybe you have both a database and an API that provide customer info), how does the system choose? That’s a more advanced topic; one approach is to rank options via a second LLM step or a simple heuristic. For now, in a prototype, it’s fine to route user requests explicitly (like if the query contains “weather” go to weather API, etc., as a fallback if the LLM isn’t reliably choosing).

9. **Prototype UI/UX:** If this is meant for business users, consider a simple chat interface or form where they input their request. Show the results clearly. In a demo, it’s often compelling to display the *constructed API call* as well (non-technical folks find it magical that their sentence turned into an API call). This also adds transparency. For example, after the user asks “What’s the weather in Belize?”, you could show a bubble that says *Calling*: `GET /weather?location=Belize` and then the answer. This mirrors how some of OpenAI’s plugins show a “Tool used” message. It helps build trust that the system did a sensible action.

10. **Learn from Text-to-SQL and Others:** Use the wealth of knowledge from text-to-SQL for things like handling ambiguities (maybe ask a follow-up if needed: *“Which John did you mean? I found 2 in the system.”), dealing with multi-turn conversation (carry context: if user first says “Find order 123”, and then “Email it to the client”, the system should remember what “it” refers to and the client info from the previous call). This enters the territory of maintaining conversational state, which is important for a polished product.

As a concrete example, let’s say you want to prototype a **“natural language to Stripe API”** for a support agent to charge or refund customers via chat. You might do the following in code (Python pseudocode using OpenAI API): 

```python
openai_model = ChatModel(...)  # GPT-4 with function calling enabled

# Define Stripe API functions for the model
functions = [
    {
      "name": "create_charge",
      "description": "Charge a customer's credit card",
      "parameters": {
        "type": "object",
        "properties": {
          "customer_id": {"type": "string", "description": "Stripe customer ID"},
          "amount": {"type": "number", "description": "Amount to charge in cents"},
          "currency": {"type": "string", "description": "Currency code, e.g. USD"}
        },
        "required": ["customer_id", "amount", "currency"]
      }
    },
    {
      "name": "create_refund",
      "description": "Issue a refund to a customer",
      "parameters": { ... }  # similar structure
    }
]

user_input = "Refund $50 to John Doe for his last order"
response = openai_model.chat(user_input, functions=functions)

if response.contains_function_call():
    func_call = response["function_call"]
    if func_call["name"] == "create_refund":
        args = json.loads(func_call["arguments"])
        # Here you would call the actual Stripe API with args
        result = call_stripe_refund(**args)
        reply = f"Okay, refunded ${args['amount']/100:.2f} to {lookup_customer_name(args['customer_id'])}."
    else:
        # handle other function
        ...
else:
    reply = response["content"]
```

In this hypothetical snippet, the model would ideally pick `create_refund` and fill in `{"customer_id": "...", "amount": 5000, "currency": "USD"}` based on the instruction. Your code then executes the Stripe API call and crafts a confirmation message. This simple loop can be expanded to more functions or chained calls as needed. The key is that the LLM handles the understanding of intent and parameter extraction, while your code handles the actual API integration and any necessary post-processing.

Finally, evaluate whether the prototype meets your usability goals. Are business users actually able to achieve tasks faster or easier with this than with traditional UIs? Often, text-to-API shines for *simple* queries (“get data quickly”) or *very complex* multi-step tasks (where orchestrating via natural language is easier than clicking through many systems). For intermediate tasks, a GUI might still be simpler. Identifying that sweet spot will help you direct the project. Keep in mind latency and reliability – users will only trust it if it’s fast enough and usually correct. With the rapid improvements in LLMs and the growing ecosystem of tools (LangChain updates, new fine-tuned models, etc.), a lot of the heavy lifting can be offloaded, leaving you to focus on the user experience and integration specifics.

In conclusion, building a text-to-API solution is **feasible today** and can deliver substantial value by simplifying how we interact with software. By starting with clear use cases, leveraging existing frameworks (OpenAPI specs, function-calling models, agent toolkits), and layering in safety, you can create a system that turns natural language into actionable API calls. This not only makes technology more accessible to non-developers but also opens up new possibilities for AI-driven automation in business workflows. As one author put it, by *“translating natural language inputs into structured API calls, LLMs extend their role far beyond conversation, becoming integral components of digital infrastructure.”* ([Teaching AI to Call APIs: Exploring Function Calling | by Maximiliano Veiga | Medium](https://medium.com/@maximilianoneto/teaching-ai-to-call-apis-exploring-function-calling-bd9beb7aeccc#:~:text=Function%20calling%20magnifies%20the%20capabilities,integral%20components%20of%20digital%20infrastructure)) With careful design, text-to-API can become a reliable bridge between human intentions and the powerful web of services available through APIs.

**Sources:** The development of text-to-API draws on recent advances in LLM tooling and research, including OpenAI’s function calling documentation ([Function Calling with LLMs | Prompt Engineering Guide<!-- --> ](https://www.promptingguide.ai/applications/function_calling#:~:text=LLMs%20like%20GPT,one%20in%20a%20single%20request)) ([Function Calling with LLMs | Prompt Engineering Guide<!-- --> ](https://www.promptingguide.ai/applications/function_calling#:~:text=,that%20interact%20with%20a%20knowledge)), LangChain’s OpenAPI agent examples ([Natural Language API Toolkits | ️ LangChain](https://python.langchain.com/docs/integrations/tools/openapi_nla/#:~:text=,and%20combine%20calls%20across%20endpoints)), the Gorilla project for API call generation ([[2305.15334] Gorilla: Large Language Model Connected with Massive APIs](https://arxiv.org/abs/2305.15334#:~:text=reasoning%20and%20program%20synthesis,issue%20of%20hallucination%2C%20commonly%20encountered)), and academic works like RestGPT ([RestGPT: Connecting LLMs with RESTful APIs](https://restgpt.github.io/#:~:text=RestGPT%20consists%20of%20three%20main,into%20two%20modules%3A%20a%20Caller)). These, along with industry perspectives on integrating AI with APIs ([AI Actions - Zapier](https://docs.zapier.com/platform/reference/ai-actions#:~:text=With%20the%20Natural%20Language%20Actions,API%2C%20you%20can)) ([Teaching AI to Call APIs: Exploring Function Calling | by Maximiliano Veiga | Medium](https://medium.com/@maximilianoneto/teaching-ai-to-call-apis-exploring-function-calling-bd9beb7aeccc#:~:text=Function%20calling%20magnifies%20the%20capabilities,integral%20components%20of%20digital%20infrastructure)), have informed the approaches and considerations discussed in this report.
